---
title: "Keyword and Sentence Extraction with TextRank (pytextrank)"
date: 2018-08-15
tags: [Machine Learning, TextRank, python, NLP]
excerpt: "TextRank is a graph based algorithm for Natural Language Processing that can be used for keyword and sentence extraction. The algorithm is inspired by PageRank which was used by Google to rank websites."
mathjax: "true"
---
### Introduction
[TextRank](https://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf) is a graph based algorithm for Natural Language Processing that can be used for keyword and sentence extraction. The algorithm is inspired by [PageRank](https://en.wikipedia.org/wiki/PageRank) which was used by Google to rank websites. For a web page $$V_i$$, $$In(V_i)$$ is the set of webpages pointing to it while $$V_j$$ is the set of vertices $$V_i$$ points to. The rank of $$V_i$$ is defined as:   
{: style="text-align: justify;"}

$$S(V_i)= (1-d) + d * \sum_{j\in{In(V_i)}} \frac{S(V_j)}{|Out(V_j)|}$$

where d is a damping factor between 0 and 1.

In the case of text, the connections can be weighted so we introduce $$w_{ij}$$ which is the weight of the edge between entity $$V_i$$ and $$V_j$$. The weighed rank of $$V_i$$ now becomes:
{: style="text-align: justify;"}

$$WS(V_i)= (1-d) + d * \sum_{V_j\in{In(V_i)}} \frac{w_{ji}}{\sum_{V_k\in{Out(V_j)}}w_{jk}}WS(V_j)$$

We have the choice of using words, collocations, or even sentences as vertices of our graph. The same goes for the connection between the vertices.
{: style="text-align: justify;"}

### Keyword extraction
For keyword extraction we want to identify a subset of terms that best describe the text. We follow these steps:

1. Tokenize and annotate with Part of Speech (PoS). Only consider single words. No n-grams used, multi-words are reconstructed later.
2. Use syntactic filter on all the lexical units (e.g. all words, nouns and verbs only).
3. Create and edge if lexical units co-occur within a window of N words to obtain an unweighted undirected graph.
4. Run the text rank algorithm to rank the words.
5. We take the top lexical words.
6. Adjacent keywords are collapsed into a multi-word keyword.

### Sentence extraction
Instead of extracting words, we extract sentences that are the most representative of the body of text using these steps:

1. Build a graph with a sentence as each node.
2. There is a connection between sentence if they are similar - this is measure by common words (after going through a syntactic filter). Similarity between sentences $$S_i$$ and $$S_j$$ is given by:

$$Similarity(S_i,S_j)= \frac{{w_k | w_k \in S_i & w_k \in S_j }}{log(|S_i|)+log(|S_j|)}$$

3. We get a weighted graph and apply the PageRank algorithm and take the top sentences.

### pytextrank
[pytextrank](https://github.com/ceteri/pytextrank) is a python implementation of TextRank, with some modifications as described on GitHub, notably verbs are included in the graph but not in the final keywords and lemmatization is used instead of stemming. Note that version 1.1.0 of `pytextrank` has errors as described in this GitHub [issue](https://github.com/ceteri/pytextrank/issues/15#issuecomment-392323261) due to an unused argument `Parse=True` when calling `spacy_nlp`. To correct for this modify the source code or use [laxatives' Pull Request](https://github.com/ceteri/pytextrank/pull/11). `pytextrank` is built on [spaCy](https://spacy.io/).

[This](https://github.com/ceteri/pytextrank/blob/master/example.ipynb) Jupyter notebook shows us how to use pytextrank. In his implementation the author choses to use iterators and write the intermediate results to json files, which can slow things down due to the IO overhead. I have [forked](https://github.com/xang1234/pytextrank) the `pytextrank` repository and modified the functions in order to avoid writing intermediate results to json files. The functions `top_keywords_sentences` allows the user to get the top keywords and sentences with ease.   

```python
def top_keywords_sentences(path,stopwords=None, spacy_nlp=None, skip_ner=True, phrase_limit=15, sent_word_limit=150):
    #Parse incoming text
    parse=parse_doc(json_iter(path))
    parse_list=[json.loads(pretty_print(i._asdict())) for i in parse]

    #Create and rank graph for keywords
    graph, ranks = text_rank(parse_list)
    norm_rank=normalize_key_phrases(parse_list, ranks, stopwords=stopwords, spacy_nlp=spacy_nlp, skip_ner=skip_ner)
    norm_rank_list=[json.loads(pretty_print(rl._asdict())) for rl in norm_rank ]
    phrases = ", ".join(set([p for p in limit_keyphrases(norm_rank_list, phrase_limit=phrase_limit)]))

    # return a matrix like result for the top keywords
    kernel = rank_kernel(norm_rank_list)

    # Rank the sentences
    top_sent=top_sentences(kernel, parse_list)
    top_sent_list=[json.loads(pretty_print(s._asdict())) for s in top_sent ]
    sent_iter = sorted(limit_sentences(top_sent_list, word_limit=sent_word_limit), key=lambda x: x[1])

    # Return ranked sentences
    s=[]
    for sent_text, idx in sent_iter:
        s.append(make_sentence(sent_text))

    graf_text = " ".join(s)

    return(graf_text,phrases)
```
### Using TextRank
TextRank is unsupervised and does not depend on language. As such the algorithm can be used for other languages. We would need a syntactic filter in our language of choice if we choose to filter out verbs. The output from TextRank can be used to summarize the text or as machine learning features.

We take a look at paper abstracts from the ACM database.
